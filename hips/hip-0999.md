---
hip: 9999
title: "Wait With kstatus"
authors: [ "@austinabro321" ]
created: "2024-12-06"
type: "feature"
status: "draft"
---

## Abstract

Currently the `--wait` flag on `helm install` and `helm upgrade` does not wait for all resources to be fully reconciled, and does not wait for custom resources (CRs) at all. By replacing the current wait logic with kstatus, Helm will achieve more intuitive waits, while simplifying it's code and documentation.

## Motivation

Certain workflows require CRDs to be ready before continuing to the next step. There is no way to tell Helm to wait for custom resources to be ready, so anyone that has this requirement must write their own logic to wait for their custom resources.

Certain workflows may want to wait until their resources are fully reconciled before continuing to their next step. For example, Helm waits for all new pods in an upgraded deployment to be ready. However, Helm does not wait for the previous pods in that deployment to be removed. Ensuring only the new pods are available after waiting for an upgrade can come in handy.

By introducing kstatus we will lower user friction with the `--wait` flag. 

## Rationale

Describe why particular design decisions were made.

## Specification

Describe the syntax and semantics of any new feature.

From a CLI user's perspective there will be no changes in how waits are called, they will still use the `--wait` flag.

Kstatus does not output any logs, Helm will supply it's own logs similar to the current logic. Helm with output a log message each second signalling that a resource is not ready. Helm will log one not ready resource at a time to not overwhelm users with output. The resource will be chosen alphabetically by `metadata.name`.

A [dynamic rest mapper](https://github.com/kubernetes-sigs/controller-runtime/blob/aea2e32a936584b06ae6f7992f856fe7292b0297/pkg/client/apiutil/restmapper.go#L36) will be used, this way if a chart installs a custom resource definition, kstatus will be able to pkc up the custom resources during wait.

<!-- TODO: Decide if we want more than alphabetically, such as - The APIVersion/Kind of the resource will determine it's priority for being logged. For example, the first log messages will always describe deployments. All deployments will be logged first. Once all deployments are in ready status, all stateful sets will be logged, and so forth.  -->

## Backwards compatibility

Describe potential impact and severity on pre-existing code.

Waiting for custom resources and for reconciliation to complete for every resource could lead to charts timing out that weren't previously.

## Security implications

No security implications

## How to teach this

Replace the [existing wait documentation](https://helm.sh/docs/intro/using_helm/) by explaining that we use kstatus and pointing to the [kstatus documentation](https://github.com/kubernetes-sigs/cli-utils/blob/master/pkg/kstatus/README.md). This comes with the added benefit of not needed to maintain Helm specific wait documentation. A separate team has already written extensive documentation on how the wait logic of kstatus works.

## Reference implementation

Once I have feedback that this HIP is in the right direction I will make a draft PR in Helm implementing this feature. 

For now, see [healthchecks.go](https://github.com/zarf-dev/zarf/blob/main/src/internal/healthchecks/healthchecks.go) in a project I maintain called Zarf. This is how we implement kstatus. After each Helm install or upgrade in Zarf, we get every resource from the chart and send them into the `WaitForReady` function. 

## Rejected ideas

TBD

## Open issues

[8661](https://github.com/helm/helm/issues/8661)

## References

existing wait documentation - https://helm.sh/docs/intro/using_helm/
kstatus documentation - https://github.com/kubernetes-sigs/cli-utils/blob/master/pkg/kstatus/README.md
Zarf kstatus implementation - 